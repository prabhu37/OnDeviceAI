RAG-based GenAI Demo App (MediaPipe LLM + Hugging Face + ObjectBox)

This demo Android application showcases Retrieval-Augmented Generation (RAG) using MediaPipe LLM Inference, sentence embedding models, and a local vector database powered by ObjectBox.
The app allows users to chat with an on-device LLM that retrieves relevant context from locally stored documents before generating responses.

✨ Features

✅ On-device LLM inference using MediaPipe GenAI

✅ Model download from Hugging Face (task-compatible)

✅ Retrieval-Augmented Generation (RAG)

✅ Sentence Embeddings for semantic similarity search

✅ Vector database using ObjectBox

✅ Fully offline inference after model download


## Demo Video

[https://user-images.githubusercontent.com/12345678/demo.mp4](https://private-user-images.githubusercontent.com/13618996/528576040-7bfa259d-fb73-4a87-af82-76329dad6046.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjYxNDI0NjgsIm5iZiI6MTc2NjE0MjE2OCwicGF0aCI6Ii8xMzYxODk5Ni81Mjg1NzYwNDAtN2JmYTI1OWQtZmI3My00YTg3LWFmODItNzYzMjlkYWQ2MDQ2Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjE5VDExMDI0OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ2MmNmMGYyYTQxNjczODg0ZTI2ZWVhMDNhMTU1NzI3NzE2NTMxMjk3ZmVlMDZlNjFlYzk0MjVhODQ5MjA1MmMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KY40WdXY3DCpOfrCOO-iF1r17fmSRjg3Bgf-6Ohl6W4)
